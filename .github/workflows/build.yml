name: Build and Test

on:
  pull_request:
    branches: [ main, develop ]
  push:
    branches: [ main ]
  schedule:
    # Run nightly at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:

# Prevent CI pileups. Keep only the latest run per branch/PR ref.
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  checks: write
  contents: read
  pull-requests: write

jobs:
  build-and-test:
    name: Build + Test (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '10.0.x'

      # Cache NuGet packages to speed up restore
      - name: Cache NuGet packages
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj', '**/Directory.Build.props') }}
          restore-keys: |
            ${{ runner.os }}-nuget-

      - name: Restore dependencies
        run: dotnet restore SmallMind.sln

      - name: Build (Release)
        run: dotnet build SmallMind.sln --no-restore --configuration Release -maxcpucount

      - name: Run Unit Tests
        run: dotnet test tests/SmallMind.Tests/SmallMind.Tests.csproj --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=unit-tests.trx"

      - name: Run Regression Tests
        run: dotnet test tests/SmallMind.Tests/SmallMind.Tests.csproj --filter "Category=Regression" --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=regression-tests.trx"

      - name: Run Integration Tests
        run: dotnet test tests/SmallMind.IntegrationTests/SmallMind.IntegrationTests.csproj --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=integration-tests.trx"

      - name: Publish Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always() && runner.os == 'Linux'
        with:
          files: |
            **/*.trx
          check_name: Test Results (${{ matrix.os }})
          comment_mode: off

  perf-smoke:
    name: Linux Perf Smoke
    runs-on: ubuntu-latest
    needs: build-and-test

    # Run on nightly schedule, manual dispatch, or PR with "perf" or "performance" label
    if: |
      github.event_name == 'schedule' ||
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'pull_request' && (contains(toJson(github.event.pull_request.labels), '"name":"perf"') || contains(toJson(github.event.pull_request.labels), '"name":"performance"')))

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '10.0.x'

      # Cache NuGet packages to speed up restore (perf job)
      - name: Cache NuGet packages
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj', '**/Directory.Build.props') }}
          restore-keys: |
            ${{ runner.os }}-nuget-

      - name: Restore dependencies
        run: dotnet restore SmallMind.sln

      - name: Build (Release)
        run: dotnet build SmallMind.sln --no-restore --configuration Release -maxcpucount

      - name: Run Performance Tests
        env:
          RUN_PERF_TESTS: 'true'
        run: dotnet test tests/SmallMind.PerfTests/SmallMind.PerfTests.csproj --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=perf-tests.trx"

      - name: Run Regression Benchmarks
        env:
          RUN_PERF_TESTS: 'true'
        run: dotnet test tests/SmallMind.PerfTests/SmallMind.PerfTests.csproj --filter "Category=Performance" --configuration Release --no-build --verbosity normal --logger "trx;LogFileName=regression-benchmarks.trx"

      - name: Run SIMD Benchmarks
        run: |
          cd benchmarks
          dotnet run --configuration Release

      - name: Run SmallMind Performance Benchmarks
        run: |
          cd src/SmallMind.Benchmarks
          dotnet run --configuration Release

      - name: Upload Benchmark Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            benchmarks/benchmark-results.md
            benchmarks/benchmark-results.json
            artifacts/perf/perf-results-latest.md
            artifacts/perf/perf-results-latest.json
          retention-days: 30

      - name: Check Performance Regressions
        run: |
          # Lenient threshold: fail only if benchmark results are entirely missing
          if [ -f "artifacts/perf/perf-results-latest.json" ]; then
            echo "✅ Performance benchmarks completed successfully"
          else
            echo "⚠️ Performance results JSON not found — checking fallback artifacts"
            if [ -f "benchmarks/benchmark-results.json" ]; then
              echo "✅ SIMD benchmark results found"
            else
              echo "❌ No benchmark results generated"
              exit 1
            fi
          fi

      - name: Publish Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always()
        with:
          files: |
            **/*.trx
          check_name: Perf & Benchmark Results
          comment_mode: off
