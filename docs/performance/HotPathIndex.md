# SmallMind Hot Path Index

**Date:** 2026-02-13  
**Purpose:** Comprehensive index of performance-critical code paths for CPU optimization  
**Scope:** All hot paths contributing >1% to inference latency

---

## Hot Path Ranking (by % of total inference time)

| Rank | Component | File | Method | % Time | Calls/Token | Priority |
|------|-----------|------|--------|--------|-------------|----------|
| 1 | Matrix Multiply | `MatMulOps.cs` | `MatMul()` | 60-70% | 48-96 | üî¥ CRITICAL |
| 2 | Quantized MatMul | `FusedQ4MatMul.cs` | `Multiply()` | 50-65% | 48-96 | üî¥ CRITICAL |
| 3 | Attention (fused) | `FusedAttentionKernels.cs` | `FusedScaledDotProductAttention()` | 15-25% | 12-24 | üî¥ CRITICAL |
| 4 | Softmax | `SoftmaxOps.cs` | `SoftmaxRow()` | 3-8% | 12-24 | üü† HIGH |
| 5 | RMSNorm | `RMSNormOps.cs` | `RMSNorm()` | 2-5% | 24-48 | üü† HIGH |
| 6 | RoPE | `RotaryEmbedding.cs` | `Apply()` | 1-3% | 12-24 | üü° MEDIUM |
| 7 | KV Cache | `OptimizedKVCache.cs` | `Append()/Get()` | 1-2% | 12-24 | üü° MEDIUM |
| 8 | GELU/Activation | `ActivationOps.cs` | `GELU()` | 0.5-2% | 12-24 | üü¢ LOW |
| 9 | Tokenizer | `BpeTokenizer.cs` | `Encode()` | 0.1-1% | 1-2 | üü¢ LOW |
| 10 | Decode Loop | `RuntimeExecutor.cs` | `Decode()` | <0.5% | 1 | üü¢ LOW |

**Note:** Percentages vary based on model size, quantization level, and sequence length.

---

## 1. Matrix Multiplication (60-70% of inference time)

### Primary File: `src/SmallMind.Core/Simd/MatMulOps.cs`

**Hot Methods:**
- `MatMul(float[] A, float[] B, float[] C, int M, int K, int N)` [Line 59]
- `MatMulAvx512()` - AVX-512 + FMA path [Line 200+]
- `MatMulAvx2()` - AVX2 + FMA fallback [Line 350+]

**Secondary File: `src/SmallMind.Core/Simd/GemmMicrokernels.cs`**
- `MatMul()` - Cache-blocked GEMM [Line 58]
- Microkernel: MR=6, NR=16 register blocking
- L1 blocking: 32√ó256√ó128 (~32KB)
- L2 blocking: 128√ó512√ó512 (~256KB)

**Current Optimization Level:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (TIER-5)
- ‚úÖ AVX-512 + FMA intrinsics
- ‚úÖ AVX2 + FMA fallback
- ‚úÖ Cache blocking (L1, L2)
- ‚úÖ Register blocking
- ‚úÖ Unsafe pointer arithmetic
- ‚úÖ Parallel.For for M ‚â• 128
- ‚úÖ [SkipLocalsInit] attribute

**Known Issues:**
- ‚ö†Ô∏è Span.Slice() in nested tile loops (5-10% overhead)
- ‚ö†Ô∏è Math.Min() not inlined in tile boundary calculations (1-2% overhead)
- ‚ö†Ô∏è Limited ARM64/NEON optimization

**Optimization Opportunities:**
1. Replace Span.Slice() with unsafe pointer arithmetic in tile loops
2. Pre-compute tile boundaries outside loops
3. Add ARM64 AdvSimd microkernel
4. Specialize for common dimensions (M=1 for decode, K%128==0)

**Per-Token Cost:**
- FP32 model: 48-96 MatMul calls per token (layers √ó attention/MLP ops)
- Q4 model: 0 FP32 MatMuls (replaced by fused Q4 MatMul)

---

## 2. Quantized Matrix Multiplication (50-65% with Q4/Q8)

### Primary File: `src/SmallMind.Quantization/Q4/FusedQ4MatMul.cs`

**Hot Methods:**
- `Multiply()` - Main dispatch [Line 40]
- `MultiplyAvx512Fused()` - Fused dequant+multiply [Line 150+]
- `MultiplyAvx2Fused()` - AVX2 fallback [Line 400+]

**Quantization Schemes:**
- Q4: 4-bit weights, 8-bit activations
- Q4K: 4-bit with k-quant blocks
- Q6K: 6-bit with k-quant blocks
- Q8: 8-bit weights and activations

**Current Optimization Level:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (TIER-5)
- ‚úÖ Fused dequantization + multiplication
- ‚úÖ AVX-512 path (16-wide vectors)
- ‚úÖ AVX2 path (8-wide vectors)
- ‚úÖ Cache blocking: L1_BLOCK_M=32, K=512, N=128
- ‚úÖ Microkernel: MR=6, NR=16
- ‚úÖ Unsafe pointer arithmetic

**Performance vs FP32:**
- Throughput: 1.8-2.2√ó faster
- Memory bandwidth: 8√ó reduction (4-bit vs 32-bit)
- Accuracy: ~95-97% of FP32

**Optimization Opportunities:**
1. Add ARM64 NEON quantized kernels
2. Optimize block-wise dequantization for smaller blocks
3. Add Q4 √ó Q8 matrix multiply variant
4. Specialize for decode (M=1, single row output)

---

## 3. Attention Mechanism (15-25% of inference time)

### Primary File: `src/SmallMind.Core/Simd/FusedAttentionKernels.cs`

**Hot Methods:**
- `FusedScaledDotProductAttention()` - Complete attention [Line 22]
- Block-wise processing: BLOCK_SIZE_Q=64, BLOCK_SIZE_K=64

**Operations Fused:**
1. Q ¬∑ K^T (dot products)
2. Scale by 1/sqrt(head_dim)
3. Causal masking
4. Softmax (stable)
5. Attention ¬∑ V (weighted sum)

**Current Optimization Level:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (TIER-5)
- ‚úÖ Flash-attention style tiling
- ‚úÖ Avoids materializing O(seq_len¬≤) attention matrix
- ‚úÖ [SkipLocalsInit] attribute
- ‚úÖ No intermediate allocations
- ‚úÖ Integrated causal masking

**Memory Savings:**
- Unfused: O(seq_len¬≤ √ó heads √ó sizeof(float)) = 64KB-4MB
- Fused: O(BLOCK_SIZE¬≤) = ~16KB scratch space

**Known Issues:**
- ‚ö†Ô∏è Softmax uses scalar exp() (not vectorized)
- ‚ö†Ô∏è QK^T dot products could use better SIMD

**Optimization Opportunities:**
1. Vectorize softmax exp() with fast approximation
2. Add AdvSimd path for ARM64
3. Optimize for small head_dim (64, 128)
4. Pre-compute 1/sqrt(head_dim) outside loop

**Per-Token Cost:**
- Decode: 12-24 attention calls (6-12 layers √ó 1-2 attention blocks)
- Prefill: Same, but seq_len √ó seq_len complexity

---

## 4. Softmax (3-8% of inference time)

### Primary File: `src/SmallMind.Core/Simd/SoftmaxOps.cs`

**Hot Methods:**
- `SoftmaxRow()` - Row-wise softmax [Line 150]
- `SoftmaxRowIndexed()` - Indexed variant [Line 220]

**Algorithm:**
1. Find max (for numerical stability)
2. Compute exp(x - max) and sum
3. Normalize by 1/sum

**Current Optimization Level:** ‚≠ê‚≠ê‚≠ê‚≠ê (TIER-4)
- ‚úÖ Vector<T> for max-finding
- ‚úÖ Fast exp approximation (Pad√© [2/2])
- ‚ö†Ô∏è Span.Slice() in SIMD loops (overhead)

**Recent Improvements:**
- Feb 2026: Added vectorized fast exp ‚Üí 60-96% faster

**Optimization Opportunities:**
1. Eliminate Span.Slice() overhead (use pointers)
2. Add AVX-512 intrinsic path
3. Add ARM64 AdvSimd path
4. Pre-compute 1/sum outside vector loop

**Per-Token Cost:**
- 12-24 softmax calls per token (one per attention head)
- Row length: 64-2048 (sequence length)

---

## 5. RMSNorm (2-5% of inference time)

### Primary File: `src/SmallMind.Core/Core/RMSNormOps.cs`

**Hot Methods:**
- `RMSNorm()` - Root mean square normalization [Line 28]

**Algorithm:**
- y = (x / rms(x)) √ó gamma
- rms(x) = sqrt(mean(x¬≤) + eps)

**Current Optimization Level:** ‚≠ê‚≠ê‚≠ê‚≠ê (TIER-4)
- ‚úÖ Vector<T> SIMD for features ‚â• 128
- ‚úÖ [AggressiveInlining | AggressiveOptimization]
- ‚úÖ Single-pass where possible
- ‚ö†Ô∏è Partial unsafe (could be fully unsafe)

**Optimization Opportunities:**
1. Full unsafe pointer arithmetic
2. Eliminate Span.Slice() in variance loop
3. Add AVX-512 path
4. Fuse with subsequent operations

**Per-Token Cost:**
- 24-48 RMSNorm calls (pre/post attention, pre/post MLP in each layer)
- Dimension: 768-4096 (model embedding size)

---

## 6. Rotary Position Embeddings (1-3% of inference time)

### Primary File: `src/SmallMind.Core/Core/RotaryEmbedding.cs`

**Hot Methods:**
- `Apply()` - Apply RoPE to Q and K [Line 80]
- `PrecomputeTables()` - One-time setup [Line 48]

**Current Optimization Level:** ‚≠ê‚≠ê‚≠ê‚≠ê (TIER-4)
- ‚úÖ Precomputed sin/cos tables
- ‚úÖ Cache-friendly table layout
- ‚úÖ In-place rotation

**Optimization Opportunities:**
1. Vectorize rotation with SIMD
2. Specialize for head_dim=64, 128
3. Fuse with attention Q/K computation

**Per-Token Cost:**
- 12-24 RoPE applications (once per attention layer for Q and K)

---

## 7. KV Cache (1-2% of inference time)

### Primary File: `src/SmallMind.Core/Core/OptimizedKVCache.cs`

**Hot Methods:**
- `Append()` - Add new token's K/V [Line 120]
- `Get()` - Retrieve cached K/V [Line 180]

**Current Optimization Level:** ‚≠ê‚≠ê‚≠ê‚≠ê (TIER-4)
- ‚úÖ Contiguous memory layout
- ‚úÖ Cache-friendly access patterns
- ‚úÖ No allocations in steady-state

**Optimization Opportunities:**
1. SIMD memcpy for large head_dim
2. Prefetch hints for next cache access
3. Optimize layout for streaming decode

**Per-Token Cost:**
- 12-24 cache operations per token (append K/V for each layer)

---

## 8. Activation Functions (0.5-2% of inference time)

### Primary File: `src/SmallMind.Core/Simd/ActivationOps.cs`

**Hot Methods:**
- `GELU()` - Gaussian Error Linear Unit [Line 80]
- `ReLU()` - Rectified Linear Unit [Line 40]

**Current Optimization Level:** ‚≠ê‚≠ê‚≠ê‚≠ê (TIER-4)
- ‚úÖ Vector<T> SIMD
- ‚úÖ Fast GELU approximation
- ‚úÖ Branchless where possible

**Optimization Opportunities:**
1. Add AVX-512 intrinsic paths
2. Lookup tables for exp in GELU
3. Fuse with subsequent operations

**Per-Token Cost:**
- 12-24 activation calls (MLP layers)

---

## 9. Tokenizer (0.1-1% of inference time)

### Primary File: `src/SmallMind.Tokenizers/Text/BpeTokenizer.cs`

**Hot Methods:**
- `Encode(string)` - String ‚Üí token IDs
- `Decode(ReadOnlySpan<int>)` - Token IDs ‚Üí string

**Current Optimization Level:** ‚≠ê‚≠ê‚≠ê (TIER-3)
- ‚ö†Ô∏è Dictionary-based BPE merges
- ‚ö†Ô∏è String allocations in Encode()
- ‚úÖ Span-based decode available

**Optimization Opportunities:**
1. Replace string allocations with Span<byte>
2. Trie-based merge lookup (O(1) vs O(n))
3. Cache frequent token sequences
4. SIMD UTF-8 validation

**Per-Token Cost:**
- Encode: Once per prompt
- Decode: Once per generated token (for display)

---

## 10. Decode Loop (< 0.5% of inference time)

### Primary File: `src/SmallMind.Runtime/RuntimeExecutor.cs`

**Hot Methods:**
- `Decode()` - Single token generation [Line 117]
- `Prefill()` - Prompt processing [Line 41]

**Current Optimization Level:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (TIER-5)
- ‚úÖ Tensor reuse (_decodeTensor)
- ‚úÖ Position offset-aware
- ‚úÖ Zero allocations in steady-state
- ‚ö†Ô∏è Position cache dictionary (unbounded growth)

**Optimization Opportunities:**
1. Bounded position cache with LRU eviction
2. ArrayPool for position embeddings
3. Inline hot path (Prefill vs Decode separation)

**Per-Token Cost:**
- 1 decode call per token

---

## Allocation Budget (Per Token)

**Current State:**
- Steady-state decode: **0 allocations** ‚úÖ
- Position cache: **Unbounded growth** ‚ö†Ô∏è
- Tokenizer: **1-2 allocations per token** (decode to string) ‚ö†Ô∏è

**Target:**
- Decode: 0 allocations
- Position cache: Bounded, reusable
- Tokenizer: 0 allocations (use Span APIs)

---

## Branch Predictability Analysis

**Predictable Branches (good):**
- Tile boundary checks (loop invariant)
- SIMD availability checks (constant per process)
- Quantization format (constant per model)

**Unpredictable Branches (bad):**
- Causal masking (data-dependent)
- Token sampling (random)
- Dynamic sequence lengths (varies)

**Mitigation:**
- Pre-compute masks
- Branchless selection
- Specialize for common cases

---

## Architecture-Specific Tuning

### x86_64 (Intel/AMD)

**Supported Intrinsics:**
- ‚úÖ AVX-512 (Skylake-X+, Ice Lake+)
- ‚úÖ AVX2 + FMA (Haswell+, Zen 2+)
- ‚úÖ AVX (Sandy Bridge+, Zen+)

**Tuning:**
- Tile sizes: 64 (L1), 256 (L2)
- Register blocking: MR=6, NR=16 (AVX-512)
- FMA for all multiply-accumulate

### ARM64 (Apple Silicon, AWS Graviton)

**Supported Intrinsics:**
- ‚úÖ AdvSimd (NEON) - all ARM64
- ‚ö†Ô∏è Limited optimization vs x86_64

**Tuning:**
- Tile sizes: TBD (test on M1/M2/M3)
- Register blocking: TBD
- Need AdvSimd microkernels

**Action Items:**
1. Implement AdvSimd MatMul
2. Implement AdvSimd quantized kernels
3. Benchmark on Apple Silicon

---

## Optimization Priority Matrix

| Component | Impact | Effort | ROI | Status |
|-----------|--------|--------|-----|--------|
| MatMul Span.Slice() | üî¥ HIGH | üü¢ LOW | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | üìã Planned |
| ARM64 MatMul | üî¥ HIGH | üî¥ HIGH | ‚≠ê‚≠ê‚≠ê‚≠ê | üìã Planned |
| Devirtualize Modules | üü† MEDIUM | üü† MEDIUM | ‚≠ê‚≠ê‚≠ê | üìã Planned |
| Softmax Span.Slice() | üü† MEDIUM | üü¢ LOW | ‚≠ê‚≠ê‚≠ê‚≠ê | üìã Planned |
| Tokenizer Allocs | üü° LOW | üü† MEDIUM | ‚≠ê‚≠ê | üìã Planned |
| Position Cache Bounds | üü° LOW | üü¢ LOW | ‚≠ê‚≠ê‚≠ê | üìã Planned |
| RMSNorm Unsafe | üü° LOW | üü¢ LOW | ‚≠ê‚≠ê | üìã Planned |
| Pre-compute Bounds | üü° LOW | üü¢ LOW | ‚≠ê‚≠ê | üìã Planned |

**Legend:**
- Impact: üî¥ HIGH (>5% gain) | üü† MEDIUM (2-5%) | üü° LOW (<2%)
- Effort: üî¥ HIGH (>2 days) | üü† MEDIUM (1-2 days) | üü¢ LOW (<1 day)
- ROI: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellent | ‚≠ê‚≠ê‚≠ê‚≠ê Good | ‚≠ê‚≠ê‚≠ê Fair | ‚≠ê‚≠ê Low

---

## Testing Strategy

**Per Optimization:**
1. Run unit tests (correctness)
2. Run perf benchmarks (before/after)
3. Measure allocations (dotTrace or custom)
4. Validate on x86_64 AND ARM64

**Golden Tests:**
- Deterministic output mode must pass
- Numerical tolerance: 1e-5f for FP32, 1e-2f for Q4

**Performance Regression Tests:**
- MatMul: ‚â•30 GFLOPS (x86_64), ‚â•15 GFLOPS (ARM64)
- Tokens/sec: ‚â•37 tok/s (small model), ‚â•15 tok/s (medium model)
- Allocations: 0 per token in decode

---

## Next Steps

1. ‚úÖ Create this HotPathIndex.md
2. ‚è≥ Run baseline performance measurements
3. ‚è≥ Implement Span.Slice() elimination (Phase 1)
4. ‚è≥ Add ARM64 kernels (Phase 2)
5. ‚è≥ Module devirtualization (Phase 3)
6. ‚è≥ Final validation and documentation

**Estimated Timeline:** 5-7 days for all phases
**Estimated Gain:** +20-40% tokens/sec (combined)
