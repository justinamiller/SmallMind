# SmallMind Performance & Memory Profiling Report

**Report Generated:** 2026-02-04 02:02:49  
**Comparison Against:** Previous run from 2026-02-03 23:06:46

---

## üìä Executive Summary

### Overall Performance Metrics

| Metric | Current Run | Previous Run | Delta | Change |
|--------|-------------|--------------|-------|---------|
| **Total Runtime** | 9,237.19 ms | 5,927.60 ms | +3,309.56 ms | +55.8% ‚ö†Ô∏è |
| **Total Memory Allocated** | 338.62 MB | 2,550.03 MB | -2,211.42 MB | -86.7% ‚úÖ |
| **Methods Profiled** | 29 | 29 | 0 | - |
| **Average Method Time** | 318.52 ms | 204.40 ms | +114.12 ms | +55.8% ‚ö†Ô∏è |

### Key Observations

üéØ **Mixed Results:**
- ‚úÖ **Massive memory optimization** - 86.7% reduction in allocations
- ‚ö†Ô∏è **Runtime regression** - 55.8% slower overall
- ‚úÖ **Improved Small Model** - 16.5% faster
- ‚ö†Ô∏è **Degraded Medium Model** - 55.1% slower

---

## üî• Core Performance Metrics

### Top 5 Hot Paths (Current Run)

| Rank | Method | Time (ms) | % of Total | Calls | Avg Time | Allocations |
|------|--------|-----------|------------|-------|----------|-------------|
| 1 | `Model_Medium_Inference` | 1,863.27 | 20.2% | 1 | 1,863 ms | 83.10 MB |
| 2 | `Model_Medium_GenerateToken` | 1,863.22 | 20.2% | 25 | 74.5 ms | 83.10 MB |
| 3 | `Model_Medium_Forward` | 1,862.82 | 20.2% | 25 | 74.5 ms | 83.10 MB |
| 4 | `MatMul_512x512` | 905.90 | 9.8% | 1 | 905.9 ms | 0.00 MB |
| 5 | `MatMul_Iteration` | 775.87 | 8.4% | 12 | 64.7 ms | 0.00 MB |

**Total Coverage:** Top 5 methods account for **78.8%** of total runtime.

### Matrix Multiplication Performance (SIMD Operations)

| Matrix Size | Current Time | Previous Time | Delta | Change | GFLOPS |
|-------------|--------------|---------------|-------|--------|--------|
| 64√ó64 | 7.39 ms | 7.07 ms | +0.32 ms | +4.5% | 0.07 |
| 128√ó128 | 13.29 ms | 3.54 ms | +9.75 ms | +275.4% ‚ö†Ô∏è | 0.32 |
| 256√ó256 | 112.93 ms | 19.59 ms | +93.34 ms | +476.5% ‚ö†Ô∏è | 0.30 |
| 512√ó512 | 905.90 ms | 172.11 ms | +733.79 ms | +426.3% ‚ö†Ô∏è | 0.30 |

**Analysis:** Severe performance regression in larger matrix multiplications. This is the primary driver of overall slowdown.

### Activation Functions Performance

| Operation | Size | Current Time | Previous Time | Delta | Change |
|-----------|------|--------------|---------------|-------|--------|
| GELU | 1,000 | 1.02 ms | 2.28 ms | -1.26 ms | -55.3% ‚úÖ |
| GELU | 10,000 | 2.30 ms | 1.17 ms | +1.13 ms | +96.6% ‚ö†Ô∏è |
| GELU | 100,000 | 20.16 ms | 11.06 ms | +9.10 ms | +82.3% ‚ö†Ô∏è |
| GELU | 1,000,000 | 202.40 ms | 100.60 ms | +101.80 ms | +101.2% ‚ö†Ô∏è |
| **Softmax** | 256 | 2.47 ms | 7.21 ms | -4.74 ms | -65.7% ‚úÖ |
| Softmax | 512 | 0.07 ms | 0.06 ms | +0.01 ms | +16.7% |
| Softmax | 1024 | 0.15 ms | 0.15 ms | 0.00 ms | 0.0% |
| Softmax | 2048 | 0.26 ms | 6.22 ms | -5.96 ms | -95.8% ‚úÖ |

**Analysis:** Mixed results - Softmax operations significantly improved, GELU operations regressed.

---

## üíæ Memory Optimization Metrics

### Memory Allocation Profile

| Component | Current Alloc | Previous Alloc | Reduction | % Reduced |
|-----------|--------------|----------------|-----------|-----------|
| **Model Medium Inference** | 83.10 MB | 729.97 MB | 646.87 MB | -88.6% ‚úÖ |
| **Model Small Inference** | 19.00 MB | 109.26 MB | 90.26 MB | -82.6% ‚úÖ |
| **Model Medium Creation** | 26.41 MB | 26.45 MB | 0.04 MB | -0.2% |
| **Model Small Creation** | 3.61 MB | 3.61 MB | 0.00 MB | 0.0% |
| **Tensor Operations** | 1.52 MB | 1.52 MB | 0.00 MB | 0.0% |

### Memory Benchmark Results

#### TensorPool Performance
```
Baseline (No Pooling):
  Allocations: 2.08 MB
  Gen0 Collections: 0
  
With Pooling:
  Allocations: 0.12 MB
  Gen0 Collections: 0
  
Improvement: 94.4% allocation reduction
```

#### In-Place Operations
```
Baseline (Allocating):
  Allocations: 2.09 MB
  Time: 4ms
  
In-Place (Reusing Destination):
  Allocations: 0.04 MB
  Time: 2ms
  
Improvement: 98.1% allocation reduction, 50% faster
```

#### Fused LayerNorm
```
Batch Size: 32, Features: 512
Allocations: 0.70 KB (1000 iterations)
Gen0 Collections: 0
Average Time: 0.250 ms
Throughput: 65.7M elements/sec

‚úì Zero allocations - fully fused!
```

### Allocation Profiler Results

#### MatMul Backward Pass
```
Matrix dimensions: 128√ó256 @ 256√ó128 = 128√ó128
Iterations: 100
Total time: 1,161 ms
Avg time per iteration: 11.61 ms

Memory Metrics:
  Total allocations: 13.00 MB
  Allocations per iteration: 133.11 KB
  Expected WITHOUT pooling: 25.00 MB
  Estimated reduction: 48.0%
```

#### Training Workload
```
Steps: 50, Batch size: 32, Hidden size: 256
Total time: 157 ms
Avg time per step: 3.15 ms

Memory Metrics:
  Total allocations: 3.77 MB
  Allocations per step: 77.25 KB
  Expected WITHOUT pooling: 62.50 MB
  Estimated reduction: 94.0%
  
‚úì Zero Gen0 collections - excellent memory pressure reduction!
```

---

## üéØ Model Performance Comparison

### Small Model (128 dim, 2 layers, 470K params)

| Metric | Current | Previous | Delta | Change |
|--------|---------|----------|-------|---------|
| **Total Inference Time** | 443.94 ms | 531.64 ms | -87.70 ms | -16.5% ‚úÖ |
| **Token Generation Time** | 443.88 ms | 531.59 ms | -87.71 ms | -16.5% ‚úÖ |
| **Forward Pass Time** | 441.38 ms | 529.00 ms | -87.62 ms | -16.6% ‚úÖ |
| **Tokens per Second** | 56.31 tok/s | 47.04 tok/s | +9.27 tok/s | +19.7% ‚úÖ |
| **Latency per Token** | 17.76 ms | 21.26 ms | -3.50 ms | -16.5% ‚úÖ |
| **Memory per Token** | 0.76 MB | 4.37 MB | -3.61 MB | -82.6% ‚úÖ |
| **Creation Time** | 20.21 ms | 34.51 ms | -14.30 ms | -41.4% ‚úÖ |

**Verdict:** ‚úÖ **Excellent** - Across the board improvements!

### Medium Model (256 dim, 4 layers, 3.45M params)

| Metric | Current | Previous | Delta | Change |
|--------|---------|----------|-------|---------|
| **Total Inference Time** | 1,863.27 ms | 1,201.28 ms | +661.99 ms | +55.1% ‚ö†Ô∏è |
| **Token Generation Time** | 1,863.22 ms | 1,201.18 ms | +662.04 ms | +55.1% ‚ö†Ô∏è |
| **Forward Pass Time** | 1,862.82 ms | 1,200.76 ms | +662.06 ms | +55.1% ‚ö†Ô∏è |
| **Tokens per Second** | 13.42 tok/s | 20.81 tok/s | -7.39 tok/s | -35.5% ‚ö†Ô∏è |
| **Latency per Token** | 74.53 ms | 48.05 ms | +26.48 ms | +55.1% ‚ö†Ô∏è |
| **Memory per Token** | 3.32 MB | 29.20 MB | -25.88 MB | -88.6% ‚úÖ |
| **Creation Time** | 54.53 ms | 84.98 ms | -30.45 ms | -35.8% ‚úÖ |

**Verdict:** ‚ö†Ô∏è **Mixed** - Memory greatly improved, but runtime significantly worse.

### Scaling Analysis

| Metric | Value | Analysis |
|--------|-------|----------|
| **Parameter Ratio** (Medium/Small) | 7.34x | Medium has 7.3√ó more parameters |
| **Time Ratio** (Current) | 4.20x | Medium is 4.2√ó slower |
| **Time Ratio** (Previous) | 2.26x | Medium was 2.3√ó slower |
| **Computational Efficiency** | 1.74x | Non-linear scaling (higher = less efficient) |
| **Memory Efficiency** | 4.37x | Medium uses 4.4√ó more memory per token |

**Scaling Verdict:** Medium model is scaling worse than before. The 7.3√ó parameter increase should ideally result in ~7.3√ó time increase for linear scaling, but we're seeing 4.2√ó, which is actually better than linear for compute. However, the regression from 2.3√ó to 4.2√ó suggests optimization issues.

---

## üìà Trend Analysis

### Top 10 Performance Improvements

| Method | Previous (ms) | Current (ms) | Improvement | Change % |
|--------|---------------|--------------|-------------|----------|
| 1. `Softmax_2048` | 6.22 | 0.26 | -5.96 ms | -95.8% ‚úÖ |
| 2. `Softmax_Iteration` | 6.36 | 0.44 | -5.92 ms | -93.1% ‚úÖ |
| 3. `TensorAdd_10000` | 10.84 | 2.24 | -8.60 ms | -79.3% ‚úÖ |
| 4. `TensorAdd_Iteration` | 10.83 | 2.23 | -8.60 ms | -79.4% ‚úÖ |
| 5. `Softmax_256` | 7.21 | 2.47 | -4.74 ms | -65.7% ‚úÖ |
| 6. `BroadcastAdd_100x100` | 6.93 | 2.40 | -4.53 ms | -65.4% ‚úÖ |
| 7. `BroadcastAdd_Iteration` | 6.91 | 2.39 | -4.52 ms | -65.4% ‚úÖ |
| 8. `GELU_1000` | 2.28 | 1.02 | -1.26 ms | -55.3% ‚úÖ |
| 9. `Model_Small_Forward` | 529.00 | 441.38 | -87.62 ms | -16.6% ‚úÖ |
| 10. `Model_Small_GenerateToken` | 531.59 | 443.88 | -87.71 ms | -16.5% ‚úÖ |

### Top 10 Performance Regressions

| Method | Previous (ms) | Current (ms) | Regression | Change % |
|--------|---------------|--------------|------------|----------|
| 1. `MatMul_512x512` | 172.11 | 905.90 | +733.79 ms | +426.3% ‚ö†Ô∏è |
| 2. `Model_Medium_Forward` | 1200.76 | 1862.82 | +662.06 ms | +55.1% ‚ö†Ô∏è |
| 3. `Model_Medium_GenerateToken` | 1201.18 | 1863.22 | +662.04 ms | +55.1% ‚ö†Ô∏è |
| 4. `Model_Medium_Inference` | 1201.28 | 1863.27 | +661.99 ms | +55.1% ‚ö†Ô∏è |
| 5. `MatMul_Iteration` | 148.10 | 775.87 | +627.77 ms | +423.9% ‚ö†Ô∏è |
| 6. `GELU_1000000` | 100.60 | 202.40 | +101.80 ms | +101.2% ‚ö†Ô∏è |
| 7. `GELU_Iteration` | 90.44 | 186.08 | +95.64 ms | +105.7% ‚ö†Ô∏è |
| 8. `MatMul_256x256` | 19.59 | 112.93 | +93.34 ms | +476.5% ‚ö†Ô∏è |
| 9. `MatMul_128x128` | 3.54 | 13.29 | +9.75 ms | +275.4% ‚ö†Ô∏è |
| 10. `GELU_100000` | 11.06 | 20.16 | +9.10 ms | +82.3% ‚ö†Ô∏è |

---

## üîç Root Cause Analysis

### Why did MatMul regress so heavily?

The MatMul operations show the most severe regression (275-476% slower). Possible causes:

1. **Memory pooling overhead** - The 86.7% memory reduction suggests aggressive pooling was added, which may introduce overhead
2. **Cache locality issues** - Memory layout changes from pooling could harm cache performance
3. **SIMD vectorization changes** - Potential regression in SIMD optimizations
4. **Increased bounds checking** - Safety checks in pooled memory access

### Why did Softmax improve dramatically?

Softmax operations improved by 65-96%. Likely causes:

1. **Algorithm optimization** - Possibly switched to fused Softmax implementation
2. **In-place operations** - Reduced allocations in Softmax path
3. **Better vectorization** - SIMD improvements for Softmax specifically

### Why did Small Model improve but Medium Model regress?

- **Small model:** Benefits from memory optimizations without hitting MatMul overhead as hard (smaller matrices)
- **Medium model:** Dominated by large MatMul operations (512√ó512) which regressed heavily
- **Scaling issue:** The regression is proportional to model size, suggesting the bottleneck scales with matrix dimensions

---

## üí° Recommendations

### Critical (Address Immediately)

1. **üî¥ Investigate MatMul regression** - 426% slowdown on 512√ó512 is unacceptable
   - Profile the MatMul implementation changes
   - Check if memory pooling is adding overhead
   - Verify SIMD vectorization is still working
   - Consider reverting recent MatMul changes

2. **üî¥ Analyze GELU performance** - 82-106% regression on larger sizes
   - Similar pattern to MatMul suggests related issue
   - May be affected by same pooling/vectorization changes

### High Priority

3. **üü° Optimize Medium model performance** - 55% regression hurts usability
   - Focus on operations that scale with model size
   - Consider separate optimization path for larger models

4. **üü° Preserve memory optimizations** - 86.7% reduction is excellent
   - Do NOT lose this gain while fixing runtime
   - Find a balance between speed and memory

### Medium Priority

5. **üü¢ Leverage Softmax improvements** - 96% improvement is impressive
   - Document what was done right
   - Apply same techniques to other operations

6. **üü¢ Scale Small model optimizations** - 16.5% improvement
   - Identify what works for Small model
   - Apply to Medium model if possible

---

## üìä Benchmark Data Summary

### System Information
- **OS:** Unix 6.11.0.1018
- **Architecture:** x64
- **CPU Cores:** 4
- **.NET Version:** 10.0.2
- **GC Mode:** Server GC

### Test Configuration
- **Small Model:** 128 embed dim, 2 layers, 4 heads, 64 block size, 256 vocab
- **Medium Model:** 256 embed dim, 4 layers, 8 heads, 128 block size, 512 vocab
- **Token Generation:** 25 tokens per inference
- **Test Runs:** 1 inference per model

### Additional Metrics

| Metric | Value |
|--------|-------|
| **Total Methods Profiled** | 29 |
| **Total Method Calls** | 201 |
| **Average Calls per Method** | 6.93 |
| **Profiling Overhead** | <1% (estimated) |

---

## üìÅ Related Reports

- **Full Code Profiler Report:** `enhanced-profile-report.md`
- **Profile Comparison:** `profile-comparison-report.md`
- **Memory Benchmark:** Console output above
- **Allocation Profiler:** Console output above
- **Previous Results:** `benchmark-results-20260204-011935/`

---

## ‚úÖ Conclusion

**Overall Assessment:** ‚ö†Ô∏è **MIXED RESULTS**

**Strengths:**
- ‚úÖ Exceptional memory optimization (-86.7% allocations)
- ‚úÖ Small model improved across all metrics
- ‚úÖ Softmax operations dramatically improved
- ‚úÖ Zero-allocation fused operations working well

**Concerns:**
- ‚ö†Ô∏è Severe MatMul regression (426% slower on 512√ó512)
- ‚ö†Ô∏è Medium model inference 55% slower
- ‚ö†Ô∏è GELU operations regressed
- ‚ö†Ô∏è Overall runtime increased 56%

**Next Steps:**
1. Investigate and fix MatMul performance regression
2. Apply lessons from Softmax improvements to other operations
3. Balance memory optimization with runtime performance
4. Re-run benchmarks after fixes to verify improvements

---

**Report End** | Generated: 2026-02-04 02:02:49
